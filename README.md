# LUMI LLM Scaling Demo (ROCm)

This repository is a handoff-ready implementation scaffold for a real-world enterprise assistant demo on LUMI (AMD MI250X), including:

- Before/after inference with a pre-trained LoRA adapter
- Live short LoRA fine-tune with distributed training (1/4/8 GPUs)
- ROCm monitoring helpers and scaling artifact generation
- Exact environment, run scripts, and presenter runbook

Start here:

1. [docs/ENVIRONMENT.md](docs/ENVIRONMENT.md)
2. [docs/SYSTEM_DESIGN.md](docs/SYSTEM_DESIGN.md)
3. [docs/DEMO_RUNBOOK.md](docs/DEMO_RUNBOOK.md)
4. [docs/HANDOFF_PLAN.md](docs/HANDOFF_PLAN.md)
